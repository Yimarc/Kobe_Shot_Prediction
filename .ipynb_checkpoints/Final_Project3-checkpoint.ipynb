{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution 1 KNN Based Feature Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6b461dec-5148-40d6-bd1a-c32d57a9f056"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "def sort_and_partition(data, name, n):\n",
    "    stat = {}\n",
    "    for i, (d, x) in enumerate(zip(data[name], data['shot_made_flag'])):\n",
    "        if not (d in stat) :\n",
    "            stat[d] = [0, 0]\n",
    "        if x == 1:\n",
    "            stat[d][0] += 1\n",
    "            stat[d][1] += 1\n",
    "        else:\n",
    "            stat[d][1] += 1\n",
    "    for key, value in stat.items():\n",
    "        stat[key] = value[0] / value[1]\n",
    "    stat = sorted(stat.items(), key=operator.itemgetter(1))\n",
    "    index_map = {}\n",
    "    for i, (key, value) in enumerate(stat):\n",
    "        index_map[key] = math.floor(i / n)\n",
    "    length = math.ceil(len(stat) / n)\n",
    "    da = {}\n",
    "    zeros = [0 for i in range(length)]\n",
    "    for i in range(length):\n",
    "        da[name + str(i)] = []\n",
    "    for i, l in enumerate(data[name]):\n",
    "        for j in range(length):\n",
    "            if j == index_map[l]:\n",
    "                da[name + str(j)].append(1)\n",
    "            else:\n",
    "                da[name + str(j)].append(0)\n",
    "    return pd.DataFrame(data = da)\n",
    "\n",
    "def sort_and_partition2(data, name, n):\n",
    "    stat = {}\n",
    "    for i, (d, x) in enumerate(zip(data[name], data['shot_made_flag'])):\n",
    "        if i < 5000:\n",
    "            continue\n",
    "        if not (d in stat) :\n",
    "            stat[d] = [0, 0]\n",
    "        if x == 1:\n",
    "            stat[d][0] += 1\n",
    "            stat[d][1] += 1\n",
    "        else:\n",
    "            stat[d][1] += 1\n",
    "    for key, value in stat.items():\n",
    "        stat[key] = value[0] / value[1]\n",
    "    stat = sorted(stat.items(), key=operator.itemgetter(1))\n",
    "    index_map = {}\n",
    "    for i, (key, value) in enumerate(stat):\n",
    "        index_map[key] = math.floor(i / n)\n",
    "    length = math.ceil(len(stat) / n)\n",
    "    da = {}\n",
    "    zeros = [0 for i in range(length)]\n",
    "    for i in range(length):\n",
    "        da[name + str(i)] = []\n",
    "    for i, l in enumerate(data[name]):\n",
    "        for j in range(length):\n",
    "            if j == index_map[l]:\n",
    "                da[name + str(j)].append(1)\n",
    "            else:\n",
    "                da[name + str(j)].append(0)\n",
    "    return pd.DataFrame(data = da)\n",
    "\n",
    "def sort_and_partition3(data, name, k = -1):\n",
    "    stat = {}\n",
    "    for i, (d, x) in enumerate(zip(data[name], data['shot_made_flag'])):\n",
    "        if not (d in stat) :\n",
    "            stat[d] = [0, 0]\n",
    "        if x == 1:\n",
    "            stat[d][0] += 1\n",
    "            stat[d][1] += 1\n",
    "        else:\n",
    "            stat[d][1] += 1\n",
    "    shoot_min = 1\n",
    "    shoot_max = 0\n",
    "    for key, v in stat.items():\n",
    "        stat[key] = v[0] / v[1]\n",
    "        if stat[key] > shoot_max:\n",
    "            shoot_max = stat[key]\n",
    "        if stat[key] < shoot_min:\n",
    "            shoot_min = stat[key]\n",
    "    if k == -1:\n",
    "        n = 1\n",
    "        stat = sorted(stat.items(), key=operator.itemgetter(1))\n",
    "        index_map = {}\n",
    "        for i, (key, value) in enumerate(stat):\n",
    "            index_map[key] = math.floor(i / n)\n",
    "        length = math.ceil(len(stat) / n)\n",
    "        da = {}\n",
    "        zeros = [0 for i in range(length)]\n",
    "        for i in range(length):\n",
    "            da[name + str(i)] = []\n",
    "        for i, l in enumerate(data[name]):\n",
    "            for j in range(length):\n",
    "                if j == index_map[l]:\n",
    "                    da[name + str(j)].append(1)\n",
    "                else:\n",
    "                    da[name + str(j)].append(0)\n",
    "        return pd.DataFrame(data = da)\n",
    "        \n",
    "    #print(stat)\n",
    "    #k-means\n",
    "    converge = False\n",
    "    while not converge:\n",
    "        c = np.random.uniform(shoot_min, shoot_max, [1, k])[0]\n",
    "        #print(c)\n",
    "        c_old = np.zeros(c.shape)\n",
    "        clusters = np.zeros(len(stat))\n",
    "        error = 0\n",
    "        for i in range(k):\n",
    "            error += abs(c_old[i] - c[i])\n",
    "        count = 0\n",
    "        while error != 0:\n",
    "            for i, (_, v) in enumerate(stat.items()):\n",
    "                distances = [abs(v - c[j]) for j in range(k)]\n",
    "                cluster = np.argmin(distances)\n",
    "                clusters[i] = cluster\n",
    "            c_old = copy.deepcopy(c)\n",
    "            for i in range(k):\n",
    "                points = [stat[key] for j, (key, _) in enumerate(stat.items()) if clusters[j] == i]\n",
    "                c[i] = np.mean(points)\n",
    "            error = 0\n",
    "            for i in range(k):\n",
    "                error += abs(c_old[i] - c[i])\n",
    "            count += 1\n",
    "            if count > 100:\n",
    "                break\n",
    "            if error == 0:\n",
    "                converge = True\n",
    "        #print('count', count)\n",
    "        #print('c', c)\n",
    "    #print('k-means result:', clusters)\n",
    "    #end k-means\n",
    "    for i, (key, _) in enumerate(stat.items()):\n",
    "        stat[key] = clusters[i]\n",
    "    \n",
    "    da = {}\n",
    "    zeros = [0 for i in range(k)]\n",
    "    for i in range(k):\n",
    "        da[name + str(i)] = []\n",
    "    for i, l in enumerate(data[name]):\n",
    "        for j in range(k):\n",
    "            if j == stat[l]:\n",
    "                da[name + str(j)].append(1)\n",
    "            else:\n",
    "                da[name + str(j)].append(0)\n",
    "    return pd.DataFrame(data = da)\n",
    "\n",
    "\n",
    "def sort_and_partition4(data, name, n):\n",
    "    stat = {}\n",
    "    for i, (d, x) in enumerate(zip(data[name], data['shot_made_flag'])):\n",
    "        if i < 5000:\n",
    "            continue\n",
    "        if not (d in stat) :\n",
    "            stat[d] = [0, 0]\n",
    "        if x == 1:\n",
    "            stat[d][0] += 1\n",
    "            stat[d][1] += 1\n",
    "        else:\n",
    "            stat[d][1] += 1\n",
    "    for key, value in stat.items():\n",
    "        stat[key] = value[0] / value[1]\n",
    "    stat = sorted(stat.items(), key=operator.itemgetter(1))\n",
    "    index_map = {}\n",
    "    for i, (key, value) in enumerate(stat):\n",
    "        index_map[key] = math.floor(i / n)\n",
    "    length = math.ceil(len(stat) / n)\n",
    "    da = {}\n",
    "    for l in data[name]:\n",
    "        if not l in index_map:\n",
    "            length += 1\n",
    "            break\n",
    "    zeros = [0 for i in range(length)]\n",
    "    for i in range(length):\n",
    "        da[name + str(i)] = []\n",
    "    for i, l in enumerate(data[name]):\n",
    "        if l in index_map:\n",
    "            for j in range(length):\n",
    "                if j == index_map[l]:\n",
    "                    da[name + str(j)].append(1)\n",
    "                else:\n",
    "                    da[name + str(j)].append(0)\n",
    "        else:\n",
    "            for j in range(length - 1):\n",
    "                da[name + str(j)].append(0)\n",
    "            da[name + str(length - 1)].append(1)\n",
    "    return pd.DataFrame(data = da)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "13b1a61f-76aa-41a8-9e4c-faf2c2eb270b"
    }
   },
   "source": [
    "# Contribution 2: Calculation of the accuracy of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def feature_accuracy(data, feature):\n",
    "    stat = {}\n",
    "    for i, (d, x) in enumerate(zip(data[feature], data['shot_made_flag'])):\n",
    "        if i < 5000:\n",
    "            continue\n",
    "        if not (d in stat) :\n",
    "            stat[d] = [0, 0]\n",
    "        if x == 1:\n",
    "            stat[d][0] += 1\n",
    "            stat[d][1] += 1\n",
    "        else:\n",
    "            stat[d][1] += 1\n",
    "    for k, v in stat.items():\n",
    "        stat[k] = v[0] / v[1]\n",
    "    dt = {feature + '_accuracy': []}\n",
    "    for l in data[feature]:\n",
    "        if l in stat:\n",
    "            dt[feature + '_accuracy'].append(stat[l])\n",
    "        else:\n",
    "            dt[feature + '_accuracy'].append(0.5)\n",
    "    return pd.DataFrame(data = dt)\n",
    "\n",
    "def normalize_feature(data, feature):\n",
    "    data[feature]=(data[feature]-data[feature].mean())/data[feature].std()\n",
    "    return 0\n",
    "\n",
    "def action_type_fransformation(data):\n",
    "    all_action_type_name = pd.unique(data['action_type'].astype('object'))\n",
    "    hit_rate = np.zeros((all_action_type_name.shape[0],1),dtype=np.float32)\n",
    "    hit_number = np.zeros((all_action_type_name.shape[0],1),dtype=np.float32)\n",
    "    i = 0\n",
    "    known_data = data.tail(25697)\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    dict_action_accuracy = pd.DataFrame(index=range(0,57))\n",
    "    for type in all_action_type_name:      \n",
    "        list1.append(type)\n",
    "        sub_type = known_data.loc[known_data['action_type'] == type]\n",
    "        nb_success_hit = sub_type.loc[sub_type['shot_made_flag'] == 1]\n",
    "        nb_success_hit = nb_success_hit.shape[0]\n",
    "        nb_fail_hit = sub_type.loc[sub_type['shot_made_flag'] == 0]\n",
    "        nb_fail_hit = nb_fail_hit.shape[0]\n",
    "        hit_number = (nb_success_hit+nb_fail_hit)\n",
    "        if hit_number <= 100:\n",
    "            new_action_type = 'half'\n",
    "            if 'Finger Roll Layup' in type:\n",
    "                new_action_type = 'forthfive'\n",
    "            if 'Driving Finger Roll' in type:\n",
    "                new_action_type = 'forthfive'\n",
    "            if 'Runinig Hook Shot' in type:\n",
    "                new_action_type = 'forthfive'\n",
    "            if 'Running Jump Shot' in type:\n",
    "                new_action_type = 'threeforth' \n",
    "            if 'Alley Oop Layup' in type:\n",
    "                new_action_type = 'threeforth'                \n",
    "            if 'Pullup Jump' in type:\n",
    "                new_action_type = 'threeforth'                \n",
    "            if 'Turnaround Fadeaway' in type:\n",
    "                new_action_type = 'threeforth'                \n",
    "            if 'Turnaround Jump Shot' in type:\n",
    "                new_action_type = 'threeforth'                \n",
    "            if 'Fadeaway Jump Shot' in type:\n",
    "                new_action_type = 'threeforth'  \n",
    "            if 'Jump Hook Shot' in type:\n",
    "                new_action_type = 'threeforth'\n",
    "            if 'Running Pull-Up' in type:\n",
    "                new_action_type = 'threeforth'\n",
    "            if 'Reverse Layup' in type:\n",
    "                new_action_type = 'threeforth'\n",
    "            if 'Runing Layup' in type:\n",
    "                new_action_type = 'threeforth'\n",
    "            if 'Bank' in type:\n",
    "                new_action_type = 'threeforth'\n",
    "            if 'Dunk' in type:\n",
    "                new_action_type = 'One'\n",
    "            if 'Turnaround Finger Roll' in type:\n",
    "                new_action_type = 'One'\n",
    "        else:\n",
    "            new_action_type = type\n",
    "        list2.append(new_action_type)\n",
    "    dict_action_accuracy['original_type_name']=pd.DataFrame(list1)\n",
    "    dict_action_accuracy['new_action_type']=pd.DataFrame(list2)\n",
    "    list = []\n",
    "    for row in data['action_type']: \n",
    "        A = dict_action_accuracy.loc[dict_action_accuracy['original_type_name'] == row]\n",
    "        B = A['new_action_type']\n",
    "        B = B.as_matrix()\n",
    "        list.append(B)\n",
    "    return pd.DataFrame(list)\n",
    "\n",
    "def action_type_fransformation2(data):\n",
    "    all_action_type_name = pd.unique(data['action_type'].astype('object'))\n",
    "    hit_rate = np.zeros((all_action_type_name.shape[0],1),dtype=np.float32)\n",
    "    hit_number = np.zeros((all_action_type_name.shape[0],1),dtype=np.float32)\n",
    "    i = 0\n",
    "    known_data = data.tail(25697)\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    dict_action_accuracy = pd.DataFrame(index=range(0,57))\n",
    "    for type in all_action_type_name:      \n",
    "        list1.append(type)\n",
    "        sub_type = known_data.loc[known_data['action_type'] == type]\n",
    "        nb_success_hit = sub_type.loc[sub_type['shot_made_flag'] == 1]\n",
    "        nb_success_hit = nb_success_hit.shape[0]\n",
    "        nb_fail_hit = sub_type.loc[sub_type['shot_made_flag'] == 0]\n",
    "        nb_fail_hit = nb_fail_hit.shape[0]\n",
    "        hit_number = (nb_success_hit+nb_fail_hit)\n",
    "        if hit_number <= 100:\n",
    "            new_action_type = 'other'\n",
    "        else:\n",
    "            new_action_type = type\n",
    "        list2.append(new_action_type)\n",
    "    dict_action_accuracy['original_type_name']=pd.DataFrame(list1)\n",
    "    dict_action_accuracy['new_action_type']=pd.DataFrame(list2)\n",
    "    list = []\n",
    "    for row in data['action_type']: \n",
    "        A = dict_action_accuracy.loc[dict_action_accuracy['original_type_name'] == row]\n",
    "        B = A['new_action_type']\n",
    "        B = B.as_matrix()\n",
    "        list.append(B)\n",
    "    return pd.DataFrame(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "6261e183-485d-43f5-aa1d-bf05805453a5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30697, 49)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "allData = pd.read_csv('data.csv', encoding='utf-8-sig')\n",
    "completeData = pd.read_csv('kobe.csv', encoding='utf-8-sig')\n",
    "referenceData = completeData[[u'GAME_ID',u'GAME_EVENT_ID',u'SHOT_MADE_FLAG']]\n",
    "referenceData['GAME_ID'] = referenceData['GAME_ID'].astype('int')\n",
    "referenceData['GAME_EVENT_ID'] = referenceData['GAME_EVENT_ID'].astype('int')\n",
    "referenceData['SHOT_MADE_FLAG'] = referenceData['SHOT_MADE_FLAG'].astype('float')\n",
    "unknown_data = allData[allData['shot_made_flag'].isnull()]#.reset_index()\n",
    "known_data = allData[allData['shot_made_flag'].notnull()]#.reset_index()\n",
    "\n",
    "for index,unknonw_i in unknown_data.iterrows():\n",
    "    game_id = unknonw_i['game_id']\n",
    "    event_id = unknonw_i['game_event_id']\n",
    "    true_i = referenceData.loc[(referenceData['GAME_ID']==(game_id)) & (referenceData['GAME_EVENT_ID'] == event_id)]    \n",
    "    true_flag = true_i['SHOT_MADE_FLAG'].values\n",
    "    unknown_data.set_value(index, 'shot_made_flag', true_flag)\n",
    "final_complete_data = unknown_data.append(known_data)\n",
    "data = final_complete_data\n",
    "\n",
    "## Home or visit\n",
    "list = []\n",
    "for row in final_complete_data['matchup']:\n",
    "    if '@' in str(row):\n",
    "        list.append(0)\n",
    "    else:\n",
    "        list.append(1)\n",
    "final_complete_data['home_field'] = pd.DataFrame(list)\n",
    "\n",
    "## Year/Month/day\n",
    "final_complete_data['game_date2'] = final_complete_data['game_date']\n",
    "final_complete_data['game_date2'] = pd.to_datetime(final_complete_data['game_date2'])\n",
    "final_complete_data['game_year'] = final_complete_data['game_date2'].dt.year\n",
    "final_complete_data['game_month'] = final_complete_data['game_date2'].dt.month\n",
    "final_complete_data['dayOfWeek'] = final_complete_data['game_date2'].dt.dayofweek\n",
    "final_complete_data['dayOfYear'] = final_complete_data['game_date2'].dt.dayofyear\n",
    "\n",
    "## Timing feature\n",
    "final_complete_data['seconds_from_period_end'] = 60 * final_complete_data['minutes_remaining'] + final_complete_data['seconds_remaining']\n",
    "final_complete_data['last_5_sec_in_period'] = final_complete_data['seconds_from_period_end'] < 5\n",
    "final_complete_data['seconds_from_period_start'] = 60*(11-final_complete_data['minutes_remaining'])+(60-final_complete_data['seconds_remaining'])\n",
    "final_complete_data['seconds_from_game_start'] = (final_complete_data['period'] <= 4).astype(int)*(final_complete_data['period']-1)*12*60 + (final_complete_data['period'] > 4).astype(int)*((final_complete_data['period']-4)*5*60 + 3*12*60) + final_complete_data['seconds_from_period_start']\n",
    "\n",
    "## Time passing\n",
    "list = []\n",
    "for period, mins, seconds in zip(final_complete_data['period'],final_complete_data['seconds_remaining'],final_complete_data['minutes_remaining']):\n",
    "    list.append((period-1)*12+(12-mins)+(60-seconds))\n",
    "final_complete_data['time_passing'] = pd.DataFrame(list)\n",
    "\n",
    "\n",
    "## Feature angle and layup\n",
    "DEGREE_UNIT = 0.001\n",
    "angles = {'angle' : [], 'layup': []}\n",
    "for x, y in zip(data['loc_x'], data['loc_y']):\n",
    "    if x == 0 and y == 0:\n",
    "        angles['angle'].append(0.0)\n",
    "        angles['layup'].append(1)\n",
    "    else:\n",
    "        angles['angle'].append(math.floor(abs(np.arctan2(y, x) * 180 / np.pi) / DEGREE_UNIT))\n",
    "        angles['layup'].append(0)\n",
    "angles = pd.DataFrame(data = angles)\n",
    "final_complete_data[\"angle\"] = angles[\"angle\"]\n",
    "final_complete_data[\"layup\"] = angles[\"layup\"]\n",
    "\n",
    "## Accuracy feature\n",
    "season_new = feature_accuracy(data, \"seconds_remaining\")\n",
    "final_complete_data[\"seconds_remaining_accuracy\"] = season_new[\"seconds_remaining_accuracy\"]\n",
    "\n",
    "season_new = feature_accuracy(data, \"shot_distance\")\n",
    "final_complete_data[\"shot_distance_accuracy\"] = season_new[\"shot_distance_accuracy\"]\n",
    "\n",
    "season_new = feature_accuracy(data, \"minutes_remaining\")\n",
    "final_complete_data[\"minutes_remaining_accuracy\"] = season_new[\"minutes_remaining_accuracy\"]\n",
    "\n",
    "season_new = feature_accuracy(data, \"period\")\n",
    "final_complete_data[\"period_accuracy\"] = season_new[\"period_accuracy\"]\n",
    "\n",
    "season_new = feature_accuracy(data, \"shot_type\")\n",
    "final_complete_data[\"shot_type_accuracy\"] = season_new[\"shot_type_accuracy\"]\n",
    "\n",
    "season_new = feature_accuracy(data, \"action_type\")\n",
    "final_complete_data[\"action_type_accuracy\"] = season_new[\"action_type_accuracy\"]\n",
    "\n",
    "season_new = feature_accuracy(data, \"lat\")\n",
    "final_complete_data[\"lat_accuracy\"] = season_new[\"lat_accuracy\"]\n",
    "\n",
    "season_new = feature_accuracy(data, \"lon\")\n",
    "final_complete_data[\"lon_accuracy\"] = season_new[\"lon_accuracy\"]\n",
    "\n",
    "season_new = feature_accuracy(data, \"season\")\n",
    "final_complete_data[\"season_accuracy\"] = season_new[\"season_accuracy\"]\n",
    "\n",
    "## Final data set\n",
    "final_complete_data = final_complete_data.reset_index()\n",
    "\n",
    "#Normalization\n",
    "normalize_feature(final_complete_data, 'loc_x')\n",
    "normalize_feature(final_complete_data, 'loc_y') \n",
    "normalize_feature(final_complete_data, 'lat') \n",
    "normalize_feature(final_complete_data, 'lon') \n",
    "normalize_feature(final_complete_data, 'period') \n",
    "normalize_feature(final_complete_data, 'time_passing') \n",
    "normalize_feature(final_complete_data, 'shot_distance') \n",
    "\n",
    "#Action_type_transform\n",
    "action_type_transform = action_type_fransformation(final_complete_data)\n",
    "final_complete_data['action_type_transform'] = action_type_transform\n",
    "final_complete_data.to_csv('Complete_Data.csv')\n",
    "print(final_complete_data.shape) \n",
    "\n",
    "#Save the data\n",
    "unknown_data = final_complete_data.head(5000)\n",
    "unknown_data.to_csv('unknown_data.csv')\n",
    "known_data = final_complete_data.tail(30697-5000)\n",
    "known_data.to_csv('known_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution 3: Heat Map Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18742722814\n",
      "-2.33472403578\n",
      "0.56526890799\n",
      "(30697, 50)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "partition = 8\n",
    "min_x, max_x =  min(final_complete_data['loc_x']), max(final_complete_data['loc_x'])\n",
    "min_y, max_y =  min(final_complete_data['loc_y']), max(final_complete_data['loc_y'])\n",
    "\n",
    "width_x = (max_x - min_x) / partition\n",
    "width_y = (max_y - min_y) / partition\n",
    "grid = []\n",
    "\n",
    "for i in range(partition):\n",
    "    start_x = min_x + (i) * width_x\n",
    "    end_x = min_x + (i + 1) * width_x\n",
    "    for j in range(partition):   \n",
    "        start_y = min_y + (j) * width_y\n",
    "        end_y = min_y + (j + 1) * width_y\n",
    "        grid.append([start_x, end_x, start_y, end_y])\n",
    "# print(len(grid))\n",
    "\n",
    "        \n",
    "grid_prob = {}\n",
    "for current_row in zip(known_data['loc_x'], known_data['loc_y'], known_data['shot_made_flag']):\n",
    "    x, y, made = current_row\n",
    "    int_made = int(made)\n",
    "    for g in grid:\n",
    "        s_x, e_x, s_y, e_y = g\n",
    "        if s_x <= x and x <= e_x and s_y <= y and y <= e_y:\n",
    "            grid_prob[((s_x + e_x)//2, (s_y + e_y)//2, int_made)] = grid_prob.get(((s_x + e_x)//2, (s_y + e_y)//2, int_made), 0) + 1\n",
    "# print(grid_prob)\n",
    "\n",
    "overall_prob = {}\n",
    "for k in grid_prob:\n",
    "    mid_x, mid_y, made = k\n",
    "    for z in grid_prob:\n",
    "        if z != k:\n",
    "            inner_mid_x, inner_mid_y, inner_made = z\n",
    "            if mid_x == inner_mid_x and mid_y == inner_mid_y:\n",
    "#                 print(grid_prob[(mid_x, mid_y, made)], grid_prob[(mid_x, mid_y, inner_made)])\n",
    "                if made == 1 and inner_made == 0:\n",
    "                    overall_prob[(mid_x, mid_y)] = grid_prob[(mid_x, mid_y, made)] / (grid_prob[(mid_x, mid_y, made)] + grid_prob[(mid_x, mid_y, inner_made)])\n",
    "                else:\n",
    "                    overall_prob[(mid_x, mid_y)] = grid_prob[(mid_x, mid_y, inner_made)] / (grid_prob[(mid_x, mid_y, made)] + grid_prob[(mid_x, mid_y, inner_made)])\n",
    "\n",
    "overall_x, overall_y, overall_val = [], [], []\n",
    "\n",
    "heat_grid = np.zeros(shape=(partition+10,partition+10))\n",
    "#print(heat_grid)\n",
    "for k, v in overall_prob.items():\n",
    "    x, y = k\n",
    "    grid_x = int((x - (min_x)) / width_x)\n",
    "    grid_y = int((y - (min_y)) / width_y)\n",
    "    overall_x.append(grid_x)\n",
    "    overall_y.append(grid_y)\n",
    "    overall_val.append(v)\n",
    "\n",
    "for x, y, v in zip(overall_x, overall_y, overall_val):\n",
    "    #print(x, y, v)\n",
    "    heat_grid[x][y] = v\n",
    "    #print('Now heat grid', heat_grid[x][y])\n",
    "\n",
    "# a = np.random.random((16, 16))\n",
    "# print(type(a))\n",
    "# print(heat_grid)\n",
    "# ax = sns.heatmap(heat_grid)\n",
    "# print(overall_x)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.bar(overall_x, overall_y, overall_val)\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# ax1 = fig.add_subplot(111, projection='3d')  \n",
    "# ax1.bar3d(overall_x, overall_y, overall_val, 1, 1, 0.5, shade=True)\n",
    "# plt.show()\n",
    "\n",
    "print(max(known_data['loc_x']))\n",
    "print(min_x)\n",
    "print(width_x)\n",
    "acc = []\n",
    "for x, y in zip(known_data['loc_x'], known_data['loc_y']):\n",
    "    grid_x = int((x - (min_x)) / width_x)\n",
    "    grid_y = int((y - (min_y)) / width_y)\n",
    "    prob = heat_grid[grid_x][grid_y]\n",
    "    acc.append(prob)\n",
    "df = pd.DataFrame({'xy_acc':acc})\n",
    "#known_data.insert(0, 'acc', acc)\n",
    "known_data['acc'] = acc\n",
    "#print(known_data)\n",
    "\n",
    "acc = []\n",
    "for x, y in zip(unknown_data['loc_x'], unknown_data['loc_y']):\n",
    "    grid_x = int((x - (min_x)) / width_x)\n",
    "    grid_y = int((y - (min_y)) / width_y)\n",
    "    prob = heat_grid[grid_x][grid_y]\n",
    "    acc.append(prob)\n",
    "df = pd.DataFrame({'xy_acc':acc})\n",
    "#unknown_data.insert(0, 'acc', acc)\n",
    "unknown_data['acc'] = acc\n",
    "final_complete_data = unknown_data.append(known_data)\n",
    "print(final_complete_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2d295cf6-13a4-45b9-bfc3-8e0baf902fca"
    }
   },
   "source": [
    "# Data pre-processing and features selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25697, 163)\n",
      "(5000, 163)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "## Decide the data set\n",
    "data = final_complete_data.copy()\n",
    "\n",
    "## Features\n",
    "#Time domain:\n",
    "seconds = sort_and_partition4(data, 'seconds_remaining', 20)\n",
    "mins = sort_and_partition4(data, 'minutes_remaining', 2)\n",
    "period2 = sort_and_partition4(data, 'period', 2)\n",
    "seasons = pd.get_dummies(data[u'season'].astype('category'))\n",
    "period = pd.get_dummies(data[u'period'].astype('category'))\n",
    "month = pd.get_dummies(data[u'game_month'].astype('category'))\n",
    "\n",
    "#Spatial domain:\n",
    "#distance = sort_and_partition4(data, 'shot_distance', 8)\n",
    "dummy_shot_type = pd.get_dummies(data[u'shot_type'])\n",
    "dummy_shot_zone_area = pd.get_dummies(data[u'shot_zone_area'].astype('category'))\n",
    "dummy_shot_zone_basic = pd.get_dummies(data[u'shot_zone_basic'].astype('category'))\n",
    "dummy_shot_zone_range = pd.get_dummies(data[u'shot_zone_range'].astype('category'))\n",
    "dummy_shot_type = pd.get_dummies(data[u'shot_type'].astype('category'))\n",
    "\n",
    "#dummy coded features\n",
    "#action_type = sort_and_partition3(data, 'action_type', 8)\n",
    "action_type = pd.get_dummies(data[u'action_type'].astype('category'))\n",
    "dummy_action_type_transform = pd.get_dummies(data[u'action_type_transform'].astype('category'))\n",
    "dummy_combined_shot_type = pd.get_dummies(data[u'combined_shot_type'].astype('category'))\n",
    "\n",
    "#Unrelevent\n",
    "dummy_opponent = pd.get_dummies(data[u'opponent'].astype('category'))\n",
    "dummy_home_feild = pd.get_dummies(data[u'home_field'].astype('category'))\n",
    "dummy_playoffs = pd.get_dummies(data[u'playoffs'].astype('category'))\n",
    "\n",
    "\n",
    "# dummy_month = pd.get_dummies(data[u'month'].astype('category'))\n",
    "\n",
    "#Final Predictors\n",
    "X = data[[#u'lat', u'lon', \n",
    "          u'loc_x',u'loc_y',   \n",
    "          #u'seconds_remaining',\n",
    "          #u'seconds_remaining_accuracy',\n",
    "          #u'minutes_remaining',\n",
    "          #u'minutes_remaining_accuracy',\n",
    "          #u'period',\n",
    "          #u'period_accuracy',\n",
    "          #u'time_passing',\n",
    "          #u'season_accuracy',\n",
    "          u'shot_distance',\n",
    "          #u'acc',\n",
    "          u'seconds_from_period_end',\n",
    "          u'last_5_sec_in_period',\n",
    "          u'seconds_from_period_start',\n",
    "          u'seconds_from_game_start',\n",
    "          u'playoffs',\n",
    "          u'home_field',\n",
    "          u'dayOfWeek',\n",
    "          u'dayOfYear',\n",
    "         ]]\n",
    "\n",
    "X = pd.concat([X, \\\n",
    "               ##-------Time\n",
    "               #seconds,\\\n",
    "               #mins, \\\n",
    "               seasons,\\\n",
    "               month,\\\n",
    "               period,\\\n",
    "               \n",
    "               ##------- Type\n",
    "               action_type,\\\n",
    "               dummy_combined_shot_type,\\\n",
    "               #dummy_action_type_transform,\\\n",
    "               \n",
    "               ##------- Spatial\n",
    "               #distance,\\\n",
    "               dummy_shot_zone_area,\\\n",
    "               dummy_shot_zone_basic,\\\n",
    "               dummy_shot_type,\\\n",
    "               dummy_shot_zone_range,\\\n",
    "               \n",
    "               ##------- Seems to be irrelevent\n",
    "               #dummy_playoffs,\n",
    "               #dummy_home_feild,\n",
    "               dummy_opponent\n",
    "               ], axis = 1)\n",
    "\n",
    "#rare_action_types = X['action_type'].value_counts().sort_values().index.values[:20]\n",
    "#X.loc[X['action_type'].isin(rare_action_types), 'action_type'] = 'Other'\n",
    "\n",
    "X_test = X.head(5000)\n",
    "X_train = X.tail(25697)\n",
    "\n",
    "#Dependent\n",
    "y = data[u'shot_made_flag']\n",
    "y_test = y.head(5000)\n",
    "y_train = y.tail(25697)\n",
    "\n",
    "#Dataframe to matrix\n",
    "X_test = X_test.as_matrix()\n",
    "X_train = X_train.as_matrix()\n",
    "y_test = y_test.as_matrix()\n",
    "y_train = y_train.as_matrix()\n",
    "\n",
    "#Print Shapoe\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category to Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seasons_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9bbb2a39efbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m           \u001b[0;31m#u'acc',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m          ]]\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'N1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseasons_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'N2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperiod_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'N3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminutes_remaining_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seasons_num' is not defined"
     ]
    }
   ],
   "source": [
    "def categorical2numeric(fulldata, feature_name):\n",
    "    all_categorical_name = pd.unique(data[feature_name])\n",
    "    number_of_category = all_categorical_name.shape[0]\n",
    "    #print(number_of_category)\n",
    "    known_data = fulldata.tail(25697)\n",
    "    list_original=[]\n",
    "    list_new=[]\n",
    "    dict_action_accuracy = pd.DataFrame(index=range(0,number_of_category))\n",
    "    i = 0\n",
    "    for category in all_categorical_name:      \n",
    "        list_original.append(category)\n",
    "        list_new.append(i)\n",
    "        i = i+1\n",
    "    dict_action_accuracy['original_category']=pd.DataFrame(list_original)\n",
    "    dict_action_accuracy['new_category']=pd.DataFrame(list_new)\n",
    "    list = []\n",
    "    for row in fulldata[feature_name]:\n",
    "        A = dict_action_accuracy.loc[dict_action_accuracy['original_category'] == row]\n",
    "        B = A['new_category']\n",
    "        B = B.as_matrix()\n",
    "        list.append(B)\n",
    "    return pd.DataFrame(list)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "## Decide the data set\n",
    "data = final_complete_data\n",
    "\n",
    "## Features\n",
    "#Time domain:\n",
    "# seasons_num = categorical2numeric(data, 'season')\n",
    "# period_num = categorical2numeric(data, 'period')\n",
    "# minutes_remaining_num = categorical2numeric(data, 'minutes_remaining')\n",
    "# seconds_remaining_num = categorical2numeric(data, 'seconds_remaining')\n",
    "\n",
    "# #Spatial domain:\n",
    "# shot_distance_num = categorical2numeric(data, 'shot_distance')\n",
    "# shot_zone_range_num = categorical2numeric(data, 'shot_zone_range')\n",
    "# shot_zone_basic_num = categorical2numeric(data, 'shot_zone_basic')\n",
    "# shot_zone_area_num = categorical2numeric(data, 'shot_zone_area')\n",
    "# shot_type_num = categorical2numeric(data, 'shot_type')\n",
    "\n",
    "# #dummy coded features\n",
    "# action_type_num = categorical2numeric(data, 'action_type')\n",
    "\n",
    "# #Unrelevent\n",
    "# opponent_num = categorical2numeric(data, 'opponent')\n",
    "# home_feild_num = categorical2numeric(data, 'home_field')\n",
    "# playoffs_num = categorical2numeric(data, 'playoffs')\n",
    "# month_num = categorical2numeric(data, 'month')\n",
    "# dummy_home_feild = pd.get_dummies(data[u'home_field'].astype('category'))\n",
    "# dummy_playoffs = pd.get_dummies(data[u'playoffs'].astype('category'))\n",
    "# dummy_month = pd.get_dummies(data[u'month'].astype('category'))\n",
    "\n",
    "#Final Predictors\n",
    "X = data[[u'lat', u'lon', \n",
    "          #u'loc_x',u'loc_y',   \n",
    "          #u'seconds_remaining',\n",
    "          #u'seconds_remaining_accuracy',\n",
    "          #u'minutes_remaining',\n",
    "          #u'minutes_remaining_accuracy',\n",
    "          #u'period',\n",
    "          #u'period_accuracy',\n",
    "          #u'time_passing',\n",
    "          #u'season_accuracy',\n",
    "          u'shot_distance',\n",
    "          #u'acc',\n",
    "         ]]\n",
    "X['N1'] = seasons_num\n",
    "X['N2'] = period_num\n",
    "X['N3'] = minutes_remaining_num\n",
    "X['N4'] = seconds_remaining_num\n",
    "X['N5'] = shot_distance_num\n",
    "#X['N6'] = shot_zone_range_num\n",
    "X['N7'] = shot_zone_basic_num\n",
    "X['N8'] = shot_zone_area_num\n",
    "#X['N9'] = shot_type_num\n",
    "X['N10'] = action_type_num\n",
    "X['N11'] = opponent_num\n",
    "X['N12'] = home_feild_num\n",
    "X['N13'] = month_num\n",
    "\n",
    "X_test = X.head(5000)\n",
    "X_train = X.tail(25697)\n",
    "\n",
    "#Dependent\n",
    "y = data[u'shot_made_flag']\n",
    "y_test = y.head(5000)\n",
    "y_train = y.tail(25697)\n",
    "\n",
    "#Dataframe to matrix\n",
    "X_test = X_test.as_matrix()\n",
    "X_train = X_train.as_matrix()\n",
    "y_test = y_test.as_matrix()\n",
    "y_train = y_train.as_matrix()\n",
    "\n",
    "#Print Shapoe\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3ac6ba3b-9200-4b3c-b493-f875e96cf6ca"
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "2b149409-74b7-4384-8960-a3c1065756e7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.680200\n",
      "Log loss test: 0.609980\n",
      "Roc: 0.696286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "\n",
    "LR = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \\\n",
    "                        intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', \\\n",
    "                        max_iter=10000, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "LR.fit(X_train,y_train)\n",
    "y_predict_proba_LR = LR.predict_proba(X_test)\n",
    "\n",
    "score_test = log_loss(y_test, y_predict_proba_LR[:,1])\n",
    "y_predict_proba_LR_train = LR.predict_proba(X_train)\n",
    "score_training= log_loss(y_train, y_predict_proba_LR_train[:,1])\n",
    "accuracy = accuracy_score(y_test, LR.predict(X_test))\n",
    "print('Accuracy: %f' %accuracy)\n",
    "#print('Log loss training: %f' %score_training)\n",
    "print('Log loss test: %f' %score_test)\n",
    "print('Roc: %f' %roc_auc_score(y_test, y_predict_proba_LR[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ca852982-293a-48e8-a468-b207b3324c2d"
    }
   },
   "source": [
    "# K-Fold Validation of LR: Testing the robustness of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "d89fced0-9410-4f68-8e7c-54bfa64eea45"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.608158\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_folds = 6\n",
    "kf = KFold(n_folds)\n",
    "kf.get_n_splits(X)\n",
    "logloss = np.zeros((1,n_folds),dtype=np.double)\n",
    "for k, (train, test) in enumerate(kf.split(X_train,y_train)):\n",
    "     LR = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \\\n",
    "                         intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', \\\n",
    "                         max_iter=10000, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "     LR.fit(X_train[train],y_train[train])\n",
    "     y_predict_proba_LR_kfold = LR.predict_proba(X_train[test])\n",
    "     logloss[0][k] = log_loss(y_train[test], y_predict_proba_LR_kfold[:,1])\n",
    "print('Log loss: %f' %np.mean(logloss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "586decd9-0bf4-421a-863e-59a59aac123a"
    }
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "7a4f144b-0728-474c-8ae9-47bb007973e7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree with gini criterion\n",
      "Log loss: 0.624448\n",
      "Accuracy: 0.681200\n",
      "RoC score: 0.669113\n",
      "Decision tree with entropy criterion\n",
      "Log loss: 0.624448\n",
      "Accuracy: 0.681200\n",
      "RoC score: 0.669113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "print('Decision tree with gini criterion')\n",
    "clf_gini = tree.DecisionTreeClassifier(criterion = 'gini', max_depth = 2)\n",
    "clf_gini.fit(X_train, y_train)\n",
    "y_predict_proba_clf_gini = clf_gini.predict_proba(X_test)\n",
    "score = log_loss(y_test, y_predict_proba_clf_gini[:,1]) \n",
    "print('Log loss: %f' %score)\n",
    "print('Accuracy: %f' %accuracy_score(y_test, clf_gini.predict(X_test)))\n",
    "print('RoC score: %f' %roc_auc_score(y_test, y_predict_proba_clf_gini[:,1]))\n",
    "\n",
    "print('Decision tree with entropy criterion')\n",
    "clf_entropy = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 2)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "y_predict_proba_clf_entropy = clf_entropy.predict_proba(X_test)\n",
    "score = log_loss(y_test, y_predict_proba_clf_entropy[:,1]) \n",
    "print('Log loss: %f' %score)\n",
    "print('Accuracy: %f' %accuracy_score(y_test, clf_entropy.predict(X_test)))\n",
    "print('RoC score: %f' %roc_auc_score(y_test, y_predict_proba_clf_entropy[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cb1bec44-1871-454b-9b54-304b62ba4a5f"
    }
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "6f07ce89-2085-46da-b4dd-45e81bdbd929"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nEstimator: 300\n",
      "Logloss: 0.621866\n",
      "Accuracy: 0.663400\n",
      "ROC: 0.687119\n",
      "nEstimator: 350\n",
      "Logloss: 0.618730\n",
      "Accuracy: 0.665400\n",
      "ROC: 0.691098\n",
      "nEstimator: 400\n",
      "Logloss: 0.619954\n",
      "Accuracy: 0.665000\n",
      "ROC: 0.690113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier)\n",
    "\n",
    "# RFC = RandomForestClassifier()\n",
    "# parameters_RFC = {'n_estimators':[100],'criterion':['entropy'],'random_state':[42]}\n",
    "# grid_search_RFC = GridSearchCV(RFC, parameters_RFC)                             \n",
    "# grid_search_RFC.fit(X_train,y_train)\n",
    "# best_n_estimators_RFC = grid_search_RFC.best_params_['n_estimators']\n",
    "# best_criterion_RFC = grid_search_RFC.best_params_['criterion']\n",
    "\n",
    "for n in range(300,450,50):\n",
    "    RFC_Best = RandomForestClassifier(n_estimators=n, criterion='entropy',n_jobs=-1)\n",
    "    RFC_Best.fit(X_train,y_train)\n",
    "    y_predict_proba_RFC = RFC_Best.predict_proba(X_test)\n",
    "    accuracy_score_RFC = accuracy_score(y_test, RFC_Best.predict(X_test))\n",
    "    roc_auc_score_RFC = roc_auc_score(y_test, y_predict_proba_RFC[:,1])\n",
    "    score = log_loss(y_test, y_predict_proba_RFC[:,1])\n",
    "    #print('The best parameter \\'n_estimators\\' is: %d' %best_n_estimators_RFC)\n",
    "    #print('The best parameter \\'criterion\\' is: %s' %best_criterion_RFC)\n",
    "    #print('The testing accuracy (accuracy_score) is: %f' %accuracy_score_RFC)\n",
    "    print('nEstimator: %d' %n)\n",
    "    print('Logloss: %f' %score)\n",
    "    print('Accuracy: %f' %accuracy_score(y_test, RFC_Best.predict(X_test)))\n",
    "    print('ROC: %f' %roc_auc_score_RFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nEstimator: 100\n",
      "Logloss: 0.657640\n",
      "Accuracy: 0.659400\n",
      "ROC: 0.677909\n",
      "nEstimator: 150\n",
      "Logloss: 0.664974\n",
      "Accuracy: 0.681200\n",
      "ROC: 0.679154\n",
      "nEstimator: 200\n",
      "Logloss: 0.669786\n",
      "Accuracy: 0.681200\n",
      "ROC: 0.679109\n",
      "nEstimator: 250\n",
      "Logloss: 0.673250\n",
      "Accuracy: 0.681200\n",
      "ROC: 0.687245\n",
      "nEstimator: 300\n",
      "Logloss: 0.675843\n",
      "Accuracy: 0.681200\n",
      "ROC: 0.693788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier)\n",
    "\n",
    "for n in range(100,350,50):\n",
    "    AdaBC_Best = AdaBoostClassifier(n_estimators=n, learning_rate=0.03, random_state=42)\n",
    "    AdaBC_Best.fit(X_train,y_train)\n",
    "    y_predict_proba_AdaBC = AdaBC_Best.predict_proba(X_test)\n",
    "    accuracy_score_AdaBC = accuracy_score(y_test, AdaBC_Best.predict(X_test))\n",
    "    roc_auc_score_AdaBC = roc_auc_score(y_test, y_predict_proba_AdaBC[:,1])\n",
    "    score = log_loss(y_test, y_predict_proba_AdaBC[:,1])\n",
    "    print('nEstimator: %d' %n)\n",
    "    print('Logloss: %f' %score)\n",
    "    print('Accuracy: %f' %accuracy_score(y_test, AdaBC_Best.predict(X_test)))\n",
    "    print('ROC: %f' %roc_auc_score_AdaBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "0.02\n",
      "6\n",
      "Logloss: 0.611358\n",
      "Accuracy: 0.681200\n",
      "ROC: 0.707634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier)\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "GBDT = GradientBoostingClassifier()\n",
    "parameters_GBDT = {'n_estimators':[90,80],'max_depth':[6,7],'learning_rate':[0.015,0.02],'random_state':[42]}\n",
    "grid_search_GBDT = GridSearchCV(GBDT, parameters_GBDT, scoring = 'neg_log_loss')                             \n",
    "grid_search_GBDT.fit(X_train,y_train)\n",
    "best_n_estimators_GBDT = grid_search_GBDT.best_params_['n_estimators']\n",
    "best_learning_rate_GBDT = grid_search_GBDT.best_params_['learning_rate']\n",
    "best_max_depth_GBDT = grid_search_GBDT.best_params_['max_depth']\n",
    "\n",
    "print(best_n_estimators_GBDT)\n",
    "print(best_learning_rate_GBDT)\n",
    "print(best_max_depth_GBDT)\n",
    "\n",
    "GBDT_Best = GradientBoostingClassifier(n_estimators=best_n_estimators_GBDT, learning_rate=best_learning_rate_GBDT, max_depth = best_max_depth_GBDT, random_state=42)\n",
    "GBDT_Best.fit(X_train,y_train)\n",
    "y_predict_proba_GBDT = GBDT_Best.predict_proba(X_test)\n",
    "accuracy_score_GBDT = accuracy_score(y_test, GBDT_Best.predict(X_test))\n",
    "roc_auc_score_GBDT = roc_auc_score(y_test, y_predict_proba_GBDT[:,1])\n",
    "score = log_loss(y_test, y_predict_proba_GBDT[:,1])\n",
    "\n",
    "print('Logloss: %f' %score)\n",
    "print('Accuracy: %f' %accuracy_score(y_test, GBDT_Best.predict(X_test)))\n",
    "print('ROC: %f' %roc_auc_score_GBDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3c570510-a566-4f00-b6e1-1a8ad4ba74cd"
    }
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "dfaa72ad-d144-4aa2-ba33-178f9a6025c1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          loc_x     loc_y  shot_distance  seconds_from_period_end  \\\n",
      "5000  -1.490226 -1.037773       0.166688                      622   \n",
      "5001  -0.981711  0.499963       0.273364                      465   \n",
      "5002   1.188558  0.955589       0.913419                      412   \n",
      "5003  -0.064568 -1.037773      -1.433451                      379   \n",
      "5004  -1.381258 -1.163070       0.060012                      572   \n",
      "5005  -0.064568 -1.037773      -1.433451                      532   \n",
      "5006  -0.654808  0.192416      -0.153340                      372   \n",
      "5007  -0.364228  0.386057      -0.153340                      216   \n",
      "5008  -0.918147  1.673200       1.233447                      116   \n",
      "5009   1.034188  0.408838       0.380040                      660   \n",
      "5010  -0.672970  0.215197      -0.153340                      429   \n",
      "5011  -0.918147 -0.992211      -0.473368                      164   \n",
      "5012  -0.273422 -0.502413      -0.900071                       76   \n",
      "5013   0.498431  1.149230       0.700067                       48   \n",
      "5014  -1.127001  1.536512       1.233447                      530   \n",
      "5015  -1.263210  0.067119       0.273364                      689   \n",
      "5016  -0.037326  0.602479       0.060012                      608   \n",
      "5017   1.152236  0.408838       0.486715                      544   \n",
      "5018  -0.209858  0.215197      -0.260016                      477   \n",
      "5019  -1.054356  0.670823       0.486715                      347   \n",
      "5020  -0.482277 -0.320163      -0.686719                      311   \n",
      "5021  -0.064568 -1.037773      -1.433451                      156   \n",
      "5022  -0.591244  1.194793       0.700067                      124   \n",
      "5023  -1.726322  1.080886       1.340123                       30   \n",
      "5024   0.707285  0.932808       0.593391                      499   \n",
      "5025  -0.037326 -0.046787      -0.580043                      382   \n",
      "5026   1.034188 -0.992211      -0.153340                       80   \n",
      "5027   1.088672 -0.650492      -0.046664                       30   \n",
      "5028   0.761769  1.058105       0.700067                      210   \n",
      "5029  -0.309745  2.060481       1.446798                        4   \n",
      "...         ...       ...            ...                      ...   \n",
      "30667 -0.064568 -1.037773      -1.433451                      598   \n",
      "30668 -0.137213 -0.434069      -0.900071                      512   \n",
      "30669  0.897978 -0.753007      -0.366692                      396   \n",
      "30670 -0.191697 -0.832742      -1.220099                      358   \n",
      "30671 -0.800098  0.910026       0.486715                      244   \n",
      "30672  0.298657  1.809887       1.233447                      573   \n",
      "30673  1.488219 -0.434069       0.380040                      228   \n",
      "30674 -0.736534 -0.855523      -0.686719                      574   \n",
      "30675 -0.064568 -1.037773      -1.433451                      531   \n",
      "30676  0.743608 -0.411288      -0.366692                      489   \n",
      "30677  0.997865 -1.037773      -0.260016                      434   \n",
      "30678  0.997865  1.422605       1.126771                      154   \n",
      "30679 -1.281372  1.422605       1.233447                      120   \n",
      "30680 -1.344936 -1.037773       0.060012                       37   \n",
      "30681 -1.090678  0.591089       0.486715                        1   \n",
      "30682  0.062561 -0.855523      -1.220099                      214   \n",
      "30683 -0.064568 -1.037773      -1.433451                       41   \n",
      "30684 -0.228019  1.935184       1.340123                        2   \n",
      "30685 -0.055487  1.422605       0.806743                      651   \n",
      "30686 -0.936308 -0.024006      -0.046664                      616   \n",
      "30687  0.670963  1.809887       1.340123                      451   \n",
      "30688  0.298657  0.101291      -0.366692                      198   \n",
      "30689 -1.208727 -0.342944      -0.046664                       67   \n",
      "30690 -0.173535  6.696473       5.713834                        0   \n",
      "30691 -1.090678  0.101291       0.166688                      697   \n",
      "30692 -0.064568 -1.037773      -1.433451                      424   \n",
      "30693 -0.055487 -0.491023      -1.006747                      365   \n",
      "30694 -1.281372  0.853073       0.806743                      208   \n",
      "30695  0.216932  2.003528       1.340123                      130   \n",
      "30696 -0.055487 -0.217647      -0.686719                       39   \n",
      "\n",
      "       last_5_sec_in_period  seconds_from_period_start  \\\n",
      "5000                  False                         98   \n",
      "5001                  False                        255   \n",
      "5002                  False                        308   \n",
      "5003                  False                        341   \n",
      "5004                  False                        148   \n",
      "5005                  False                        188   \n",
      "5006                  False                        348   \n",
      "5007                  False                        504   \n",
      "5008                  False                        604   \n",
      "5009                  False                         60   \n",
      "5010                  False                        291   \n",
      "5011                  False                        556   \n",
      "5012                  False                        644   \n",
      "5013                  False                        672   \n",
      "5014                  False                        190   \n",
      "5015                  False                         31   \n",
      "5016                  False                        112   \n",
      "5017                  False                        176   \n",
      "5018                  False                        243   \n",
      "5019                  False                        373   \n",
      "5020                  False                        409   \n",
      "5021                  False                        564   \n",
      "5022                  False                        596   \n",
      "5023                  False                        690   \n",
      "5024                  False                        221   \n",
      "5025                  False                        338   \n",
      "5026                  False                        640   \n",
      "5027                  False                        690   \n",
      "5028                  False                        510   \n",
      "5029                   True                        716   \n",
      "...                     ...                        ...   \n",
      "30667                 False                        122   \n",
      "30668                 False                        208   \n",
      "30669                 False                        324   \n",
      "30670                 False                        362   \n",
      "30671                 False                        476   \n",
      "30672                 False                        147   \n",
      "30673                 False                        492   \n",
      "30674                 False                        146   \n",
      "30675                 False                        189   \n",
      "30676                 False                        231   \n",
      "30677                 False                        286   \n",
      "30678                 False                        566   \n",
      "30679                 False                        600   \n",
      "30680                 False                        683   \n",
      "30681                  True                        719   \n",
      "30682                 False                        506   \n",
      "30683                 False                        679   \n",
      "30684                  True                        718   \n",
      "30685                 False                         69   \n",
      "30686                 False                        104   \n",
      "30687                 False                        269   \n",
      "30688                 False                        522   \n",
      "30689                 False                        653   \n",
      "30690                  True                        720   \n",
      "30691                 False                         23   \n",
      "30692                 False                        296   \n",
      "30693                 False                        355   \n",
      "30694                 False                        512   \n",
      "30695                 False                        590   \n",
      "30696                 False                        681   \n",
      "\n",
      "       seconds_from_game_start  playoffs  home_field  dayOfWeek  \\\n",
      "5000                        98         0           0          1   \n",
      "5001                       255         0           1          1   \n",
      "5002                       308         0           1          1   \n",
      "5003                      1061         0           0          1   \n",
      "5004                      1588         0           0          1   \n",
      "5005                      1628         0           0          1   \n",
      "5006                      1788         0           0          1   \n",
      "5007                      1944         0           0          1   \n",
      "5008                      2044         0           0          1   \n",
      "5009                        60         0           0          2   \n",
      "5010                       291         0           1          2   \n",
      "5011                       556         0           1          2   \n",
      "5012                       644         0           1          2   \n",
      "5013                       672         0           0          2   \n",
      "5014                       910         0           0          2   \n",
      "5015                      1471         0           0          2   \n",
      "5016                      1552         0           0          2   \n",
      "5017                      1616         0           0          2   \n",
      "5018                      1683         0           0          2   \n",
      "5019                      1813         0           1          2   \n",
      "5020                      1849         0           1          2   \n",
      "5021                      2004         0           1          2   \n",
      "5022                      2036         0           1          2   \n",
      "5023                      2130         0           1          2   \n",
      "5024                      2381         0           1          2   \n",
      "5025                      2498         0           1          2   \n",
      "5026                      2800         0           1          2   \n",
      "5027                      2850         0           1          2   \n",
      "5028                      1230         0           0          5   \n",
      "5029                      1436         0           0          5   \n",
      "...                        ...       ...         ...        ...   \n",
      "30667                     1562         1           0          4   \n",
      "30668                     1648         1           0          4   \n",
      "30669                     1764         1           0          4   \n",
      "30670                     1802         1           0          4   \n",
      "30671                     1916         1           0          4   \n",
      "30672                     2307         1           0          4   \n",
      "30673                     2652         1           0          4   \n",
      "30674                      146         1           0          0   \n",
      "30675                      189         1           0          0   \n",
      "30676                      231         1           0          0   \n",
      "30677                      286         1           0          0   \n",
      "30678                      566         1           1          0   \n",
      "30679                      600         1           1          0   \n",
      "30680                      683         1           1          0   \n",
      "30681                      719         1           1          0   \n",
      "30682                     1226         1           1          0   \n",
      "30683                     1399         1           1          0   \n",
      "30684                     1438         1           1          0   \n",
      "30685                     1509         1           1          0   \n",
      "30686                     1544         1           1          0   \n",
      "30687                     1709         1           1          0   \n",
      "30688                     1962         1           1          0   \n",
      "30689                     2093         1           1          0   \n",
      "30690                     2160         1           1          0   \n",
      "30691                     2183         1           1          0   \n",
      "30692                     2456         1           1          0   \n",
      "30693                     2515         1           1          0   \n",
      "30694                     2672         1           1          0   \n",
      "30695                     2750         1           1          0   \n",
      "30696                     2841         1           1          0   \n",
      "\n",
      "            ...        PHX  POR  SAC  SAS  SEA  TOR  UTA  VAN  WAS  \\\n",
      "5000        ...          0    1    0    0    0    0    0    0    0   \n",
      "5001        ...          0    1    0    0    0    0    0    0    0   \n",
      "5002        ...          0    1    0    0    0    0    0    0    0   \n",
      "5003        ...          0    1    0    0    0    0    0    0    0   \n",
      "5004        ...          0    1    0    0    0    0    0    0    0   \n",
      "5005        ...          0    1    0    0    0    0    0    0    0   \n",
      "5006        ...          0    1    0    0    0    0    0    0    0   \n",
      "5007        ...          0    1    0    0    0    0    0    0    0   \n",
      "5008        ...          0    1    0    0    0    0    0    0    0   \n",
      "5009        ...          0    0    0    0    0    0    1    0    0   \n",
      "5010        ...          0    0    0    0    0    0    1    0    0   \n",
      "5011        ...          0    0    0    0    0    0    1    0    0   \n",
      "5012        ...          0    0    0    0    0    0    1    0    0   \n",
      "5013        ...          0    0    0    0    0    0    1    0    0   \n",
      "5014        ...          0    0    0    0    0    0    1    0    0   \n",
      "5015        ...          0    0    0    0    0    0    1    0    0   \n",
      "5016        ...          0    0    0    0    0    0    1    0    0   \n",
      "5017        ...          0    0    0    0    0    0    1    0    0   \n",
      "5018        ...          0    0    0    0    0    0    1    0    0   \n",
      "5019        ...          0    0    0    0    0    0    1    0    0   \n",
      "5020        ...          0    0    0    0    0    0    1    0    0   \n",
      "5021        ...          0    0    0    0    0    0    1    0    0   \n",
      "5022        ...          0    0    0    0    0    0    1    0    0   \n",
      "5023        ...          0    0    0    0    0    0    1    0    0   \n",
      "5024        ...          0    0    0    0    0    0    1    0    0   \n",
      "5025        ...          0    0    0    0    0    0    1    0    0   \n",
      "5026        ...          0    0    0    0    0    0    1    0    0   \n",
      "5027        ...          0    0    0    0    0    0    1    0    0   \n",
      "5028        ...          0    0    0    0    0    0    0    1    0   \n",
      "5029        ...          0    0    0    0    0    0    0    1    0   \n",
      "...         ...        ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "30667       ...          0    0    0    0    0    0    0    0    0   \n",
      "30668       ...          0    0    0    0    0    0    0    0    0   \n",
      "30669       ...          0    0    0    0    0    0    0    0    0   \n",
      "30670       ...          0    0    0    0    0    0    0    0    0   \n",
      "30671       ...          0    0    0    0    0    0    0    0    0   \n",
      "30672       ...          0    0    0    0    0    0    0    0    0   \n",
      "30673       ...          0    0    0    0    0    0    0    0    0   \n",
      "30674       ...          0    0    0    0    0    0    0    0    0   \n",
      "30675       ...          0    0    0    0    0    0    0    0    0   \n",
      "30676       ...          0    0    0    0    0    0    0    0    0   \n",
      "30677       ...          0    0    0    0    0    0    0    0    0   \n",
      "30678       ...          0    0    0    0    0    0    0    0    0   \n",
      "30679       ...          0    0    0    0    0    0    0    0    0   \n",
      "30680       ...          0    0    0    0    0    0    0    0    0   \n",
      "30681       ...          0    0    0    0    0    0    0    0    0   \n",
      "30682       ...          0    0    0    0    0    0    0    0    0   \n",
      "30683       ...          0    0    0    0    0    0    0    0    0   \n",
      "30684       ...          0    0    0    0    0    0    0    0    0   \n",
      "30685       ...          0    0    0    0    0    0    0    0    0   \n",
      "30686       ...          0    0    0    0    0    0    0    0    0   \n",
      "30687       ...          0    0    0    0    0    0    0    0    0   \n",
      "30688       ...          0    0    0    0    0    0    0    0    0   \n",
      "30689       ...          0    0    0    0    0    0    0    0    0   \n",
      "30690       ...          0    0    0    0    0    0    0    0    0   \n",
      "30691       ...          0    0    0    0    0    0    0    0    0   \n",
      "30692       ...          0    0    0    0    0    0    0    0    0   \n",
      "30693       ...          0    0    0    0    0    0    0    0    0   \n",
      "30694       ...          0    0    0    0    0    0    0    0    0   \n",
      "30695       ...          0    0    0    0    0    0    0    0    0   \n",
      "30696       ...          0    0    0    0    0    0    0    0    0   \n",
      "\n",
      "       shot_made_flag  \n",
      "5000              0.0  \n",
      "5001              1.0  \n",
      "5002              0.0  \n",
      "5003              1.0  \n",
      "5004              0.0  \n",
      "5005              1.0  \n",
      "5006              1.0  \n",
      "5007              0.0  \n",
      "5008              0.0  \n",
      "5009              1.0  \n",
      "5010              1.0  \n",
      "5011              0.0  \n",
      "5012              0.0  \n",
      "5013              0.0  \n",
      "5014              1.0  \n",
      "5015              0.0  \n",
      "5016              0.0  \n",
      "5017              0.0  \n",
      "5018              1.0  \n",
      "5019              1.0  \n",
      "5020              1.0  \n",
      "5021              0.0  \n",
      "5022              0.0  \n",
      "5023              0.0  \n",
      "5024              0.0  \n",
      "5025              0.0  \n",
      "5026              1.0  \n",
      "5027              0.0  \n",
      "5028              1.0  \n",
      "5029              1.0  \n",
      "...               ...  \n",
      "30667             1.0  \n",
      "30668             0.0  \n",
      "30669             0.0  \n",
      "30670             0.0  \n",
      "30671             0.0  \n",
      "30672             0.0  \n",
      "30673             0.0  \n",
      "30674             0.0  \n",
      "30675             0.0  \n",
      "30676             1.0  \n",
      "30677             0.0  \n",
      "30678             1.0  \n",
      "30679             0.0  \n",
      "30680             1.0  \n",
      "30681             0.0  \n",
      "30682             0.0  \n",
      "30683             0.0  \n",
      "30684             1.0  \n",
      "30685             0.0  \n",
      "30686             0.0  \n",
      "30687             0.0  \n",
      "30688             0.0  \n",
      "30689             1.0  \n",
      "30690             0.0  \n",
      "30691             0.0  \n",
      "30692             0.0  \n",
      "30693             0.0  \n",
      "30694             1.0  \n",
      "30695             0.0  \n",
      "30696             0.0  \n",
      "\n",
      "[25697 rows x 164 columns]\n",
      "5000     0.0\n",
      "5001     1.0\n",
      "5002     0.0\n",
      "5003     1.0\n",
      "5004     0.0\n",
      "5005     1.0\n",
      "5006     1.0\n",
      "5007     0.0\n",
      "5008     0.0\n",
      "5009     1.0\n",
      "5010     1.0\n",
      "5011     0.0\n",
      "5012     0.0\n",
      "5013     0.0\n",
      "5014     1.0\n",
      "5015     0.0\n",
      "5016     0.0\n",
      "5017     0.0\n",
      "5018     1.0\n",
      "5019     1.0\n",
      "5020     1.0\n",
      "5021     0.0\n",
      "5022     0.0\n",
      "5023     0.0\n",
      "5024     0.0\n",
      "5025     0.0\n",
      "5026     1.0\n",
      "5027     0.0\n",
      "5028     1.0\n",
      "5029     1.0\n",
      "        ... \n",
      "30667    1.0\n",
      "30668    0.0\n",
      "30669    0.0\n",
      "30670    0.0\n",
      "30671    0.0\n",
      "30672    0.0\n",
      "30673    0.0\n",
      "30674    0.0\n",
      "30675    0.0\n",
      "30676    1.0\n",
      "30677    0.0\n",
      "30678    1.0\n",
      "30679    0.0\n",
      "30680    1.0\n",
      "30681    0.0\n",
      "30682    0.0\n",
      "30683    0.0\n",
      "30684    1.0\n",
      "30685    0.0\n",
      "30686    0.0\n",
      "30687    0.0\n",
      "30688    0.0\n",
      "30689    1.0\n",
      "30690    0.0\n",
      "30691    0.0\n",
      "30692    0.0\n",
      "30693    0.0\n",
      "30694    1.0\n",
      "30695    0.0\n",
      "30696    0.0\n",
      "Name: shot_made_flag, Length: 25697, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names must be unique",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fdbaf053b6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKnown_Data_Transformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shot_made_flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKnown_Data_Transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKnown_Data_Transformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shot_made_flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mdtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUnknown_Data_Transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mfeature_names\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m    655\u001b[0m                 \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_names must be unique'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'feature_names must have the same length as data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names must be unique"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "for n in [950]:\n",
    "    XGB_Best = XGBClassifier(n_estimators=n,\\\n",
    "                             learning_rate=0.004,\\\n",
    "                             max_depth=7,\\\n",
    "                             min_child_weight = 3,\\\n",
    "                             max_delta_step = 1,\\\n",
    "                             colsample_bytree = 0.7,\\\n",
    "                             objective='binary:logistic',\\\n",
    "                             n_jobs=-1,\\\n",
    "                             silent = 1,\\\n",
    "                             eval_metric = 'logloss')\n",
    "    XGB_Best.fit(X_train,y_train)\n",
    "    y_predict_proba_XGB = XGB_Best.predict_proba(X_test)\n",
    "    accuracy_score_XGB = accuracy_score(y_test, XGB_Best.predict(X_test))\n",
    "    roc_auc_score_XGB = roc_auc_score(y_test, y_predict_proba_XGB[:,1])\n",
    "    score = log_loss(y_test, y_predict_proba_XGB[:,1])\n",
    "    print(n)\n",
    "    print('Log loss: %f' %score)    \n",
    "    print('Accuracy: %f' %accuracy_score_XGB)    \n",
    "    print('ROC score: %f' %roc_auc_score_XGB)    \n",
    "\n",
    "\n",
    "# X_test = X.head(5000)\n",
    "# X_train = X.tail(25697)\n",
    "# y = data[u'shot_made_flag']\n",
    "# y_test = y.head(5000)\n",
    "# y_train = y.tail(25697)\n",
    "# Known_Data_Transformed = pd.concat([X_train,y_train],axis=1)\n",
    "# Unknown_Data_Transformed = pd.concat([X_test,y_test],axis=1)\n",
    "# print(Known_Data_Transformed)\n",
    "\n",
    "\n",
    "# # overall = pd.concat([X, y], axis=1)\n",
    "# # for i in range(5000):\n",
    "# #     overall[i:]['shot_made_flag'] = None\n",
    "# #     print(i)\n",
    "# # print(overall)\n",
    "\n",
    "# # mask = [False] * 25697\n",
    "# # for i in range(5000):\n",
    "# #     mask[i] = True\n",
    "# # df_mask = pd.DataFrame({\"mask\" : mask})\n",
    "\n",
    "\n",
    "# # data_submit = overall[df_mask]\n",
    "\n",
    "# # target = overall['shot_made_flag'].copy()\n",
    "# # Xn = overall[~df_mask]\n",
    "# # Yn = target[~df_mask]\n",
    "\n",
    "# print(Known_Data_Transformed['shot_made_flag'])\n",
    "# dtrain = xgb.DMatrix(Known_Data_Transformed, label=Known_Data_Transformed['shot_made_flag'])\n",
    "# dtest = xgb.DMatrix(Unknown_Data_Transformed)\n",
    "\n",
    "\n",
    "# params = {}\n",
    "# params['objective'] = 'binary:logistic'\n",
    "# params['eval_metric'] = 'logloss'\n",
    "# params['max_depth'] = 7\n",
    "# params['silent'] = 1\n",
    "# params['colsample_bytree'] = 0.7\n",
    "# params['eta'] = 0.004\n",
    "# params['max_delta_step'] = 1\n",
    "# params['min_child_weight'] = 3\n",
    "\n",
    "# clf = xgb.train(params, dtrain, num_boost_round=950)\n",
    "# preds = clf.predict(dtest)\n",
    "\n",
    "# logloss = log_loss(y_test, preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in fields game_date",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c62732a80fcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0munknown_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mdtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    263\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[1;32m    264\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                                                                 feature_types)\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_pandas_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[0;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    184\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[1;32m    185\u001b[0m Did not expect the data types in fields \"\"\"\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in fields game_date"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost as xgb\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "data.set_index('shot_id', inplace=True)\n",
    "\n",
    "unknown_mask = data['shot_made_flag'].isnull()\n",
    "data_cl = data.copy()\n",
    "target = data_cl['shot_made_flag'].copy()\n",
    "\n",
    "data_cl.drop('team_id', inplace=True, axis=1) #only 1 category\n",
    "data_cl.drop('lat', inplace=True, axis=1) # correlated with loc_x\n",
    "data_cl.drop('lon', inplace=True, axis=1) # correlated with loc_y\n",
    "data_cl.drop('game_id', inplace=True, axis=1) # should not be dependent on game id, furthermore it's contained in opponent/match\n",
    "data_cl.drop('game_event_id', inplace=True, axis=1) # independent, unique for every shots in a game\n",
    "data_cl.drop('team_name', inplace=True, axis=1) # always LA Lakers\n",
    "data_cl.drop('shot_made_flag', inplace=True, axis=1) # target variables\n",
    "\n",
    "# time into the game\n",
    "data_cl['seconds_from_period_end'] = 60 * data_cl['minutes_remaining'] + data_cl['seconds_remaining']\n",
    "data_cl['last_5_sec_in_period'] = data_cl['seconds_from_period_end'] < 5\n",
    "data_cl['seconds_from_period_start'] = 60*(11-data_cl['minutes_remaining'])+(60-data_cl['seconds_remaining'])\n",
    "data_cl['seconds_from_game_start'] = (data_cl['period'] <= 4).astype(int)*(data_cl['period']-1)*12*60 + (data_cl['period'] > 4).astype(int)*((data_cl['period']-4)*5*60 + 3*12*60) + data_cl['seconds_from_period_start']\n",
    "\n",
    "# drop redundant features\n",
    "data_cl.drop('minutes_remaining', axis=1, inplace=True)\n",
    "data_cl.drop('seconds_remaining', axis=1, inplace=True)\n",
    "\n",
    "data_cl['home_play'] = data_cl['matchup'].str.contains('vs').astype('int')\n",
    "data_cl.drop('matchup', axis=1, inplace=True)\n",
    "\n",
    "data_cl['game_date'] = pd.to_datetime(data_cl['game_date'])\n",
    "\n",
    "# year and month\n",
    "data_cl['game_year'] = data_cl['game_date'].dt.year\n",
    "data_cl['game_month'] = data_cl['game_date'].dt.month\n",
    "\n",
    "# day of week/year\n",
    "data_cl['dayOfWeek'] = data_cl['game_date'].dt.dayofweek\n",
    "data_cl['dayOfYear'] = data_cl['game_date'].dt.dayofyear\n",
    "\n",
    "\n",
    "#data_cl.drop('combined_shot_type', axis=1, inplace=True)\n",
    "data_cl.drop('game_year', axis=1, inplace=True)\n",
    "data_cl.drop('seconds_from_period_end', axis=1, inplace=True)\n",
    "#data_cl.drop('last_5_sec_in_period', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#rare_action_types = data_cl['action_type'].value_counts().sort_values().index.values[:20]\n",
    "#data_cl.loc[data_cl['action_type'].isin(rare_action_types), 'action_type'] = 'Other'\n",
    "\n",
    "categorial_cols = [\n",
    "    'action_type', 'combined_shot_type', 'period', 'season', 'shot_type',\n",
    "    'shot_zone_area', 'shot_zone_basic', 'shot_zone_range',\n",
    "    'game_month', 'opponent']\n",
    "\n",
    "for cc in categorial_cols:\n",
    "    dummies = pd.get_dummies(data_cl[cc])\n",
    "    dummies = dummies.add_prefix(\"{}_\".format(cc))\n",
    "    data_cl.drop(cc, axis=1, inplace=True)\n",
    "    data_cl = data_cl.join(dummies)\n",
    "    \n",
    "data_submit = data_cl[unknown_mask]\n",
    "# Separate dataset for training\n",
    "X = data_cl[~unknown_mask]\n",
    "Y = target[~unknown_mask]\n",
    "\n",
    "dtrain = xgb.DMatrix(X, label=Y)\n",
    "dtest = xgb.DMatrix(data_submit)\n",
    "\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['max_depth'] = 7\n",
    "params['silent'] = 1\n",
    "params['colsample_bytree'] = 0.7\n",
    "params['eta'] = 0.004\n",
    "params['max_delta_step'] = 1\n",
    "params['min_child_weight'] = 3\n",
    "\n",
    "clf = xgb.train(params, dtrain, num_boost_round=950)\n",
    "preds = clf.predict(dtest)\n",
    "\n",
    "logloss = log_loss(y_test, preds)\n",
    "print(logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.631404\n",
      "Log loss training: 0.610752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#for n in range(20,200,50):\n",
    "NN = MLPClassifier(solver='adam', activation='tanh', alpha=0.08, hidden_layer_sizes=(100,100,100,100,40,30,30,20,10,10,10,8,5,5), random_state=1)\n",
    "NN.fit(X_train, y_train)                         \n",
    "y_predict_proba_NN = NN.predict_proba(X_test)\n",
    "accuracy_score_NN = accuracy_score(y_test, NN.predict(X_test))\n",
    "roc_auc_score_NN = roc_auc_score(y_test, y_predict_proba_NN[:,1])\n",
    "score = log_loss(y_test, y_predict_proba_NN[:,1])\n",
    "y_predict_proba_NN_train = NN.predict_proba(X_train)\n",
    "score_training= log_loss(y_train, y_predict_proba_NN_train[:,1])\n",
    "print('Log loss: %f' %score)\n",
    "print('Log loss training: %f' %score_training)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCGEUPh/8e1G1Ss3WjYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a22f44cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# LR\n",
    "fpr_LR, tpr_LR, thresholds_LR = roc_curve(y_test, y_predict_proba_LR[:,1])\n",
    "AUC_LR = roc_auc_score(y_test, y_predict_proba_LR[:,1])\n",
    "\n",
    "# DT with gini\n",
    "fpr_gini, tpr_gini, thresholds_gini = roc_curve(y_test, y_predict_proba_clf_gini[:,1])\n",
    "AUC_gini = roc_auc_score(y_test, y_predict_proba_clf_gini[:,1])\n",
    "\n",
    "# DT with entropy\n",
    "fpr_entropy, tpr_entropy, thresholds_entropy = roc_curve(y_test, y_predict_proba_clf_entropy[:,1])\n",
    "AUC_entropy = roc_auc_score(y_test, y_predict_proba_clf_entropy[:,1])\n",
    "\n",
    "# Random Forest\n",
    "fpr_RF, tpr_RF, thresholds_RF = roc_curve(y_test, y_predict_proba_RFC[:,1])\n",
    "AUC_RF = roc_auc_score(y_test, y_predict_proba_RFC[:,1])\n",
    "\n",
    "# AdaBoost\n",
    "fpr_Ada, tpr_Ada, thresholds_Ada = roc_curve(y_test, y_predict_proba_Ada[:,1])\n",
    "AUC_Ada = roc_auc_score(y_test, y_predict_proba_Ada[:,1])\n",
    "\n",
    "# GBDT\n",
    "fpr_GBDT, tpr_GBDT, thresholds_GBDT = roc_curve(y_test, y_predict_proba_GBC[:,1])\n",
    "AUC_GBDT = roc_auc_score(y_test, y_predict_proba_GBC[:,1])\n",
    "\n",
    "# XGBoost\n",
    "fpr_XGB, tpr_XGB, thresholds_XGB = roc_curve(y_test, y_predict_proba_XGB[:,1])\n",
    "AUC_XGB = roc_auc_score(y_test, y_predict_proba_XGB[:,1])\n",
    "\n",
    "LR_plot, = plt.plot(fpr_LR, tpr_LR, 'g', label=\"Logistic: AUC = \" + str(AUC_LR))\n",
    "GINI_plot, = plt.plot(fpr_gini, tpr_gini, 'r', label=\"DT with gini: AUC = \" + str(AUC_gini))\n",
    "ENTROPY_plot, = plt.plot(fpr_entropy, tpr_entropy, 'b', label=\"DT with entropy: AUC = \" + str(AUC_entropy))\n",
    "RF_plot, = plt.plot(fpr_RF, tpr_RF, 'm', label=\"Random forest: AUC = \" + str(AUC_RF))\n",
    "Ada_plot, = plt.plot(fpr_Ada, tpr_Ada, 'c', label=\"AdaBoost: AUC = \" + str(AUC_Ada))\n",
    "GBDT_plot, = plt.plot(fpr_GBDT, tpr_GBDT, 'y', label=\"GBDT: AUC = \" + str(AUC_GBDT))\n",
    "XGB_plot, = plt.plot(fpr_XGB, tpr_XGB, 'k', label=\"XGBoost: AUC = \" + str(AUC_XGB))\n",
    "\n",
    "plt.legend(handles=[LR_plot, GINI_plot, ENTROPY_plot, RF_plot, Ada_plot, GBDT_plot, XGB_plot])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution 4: Time Series Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.681400\n",
      "log loss 0.608944\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "\n",
    "## Decide the training set\n",
    "data = final_complete_data\n",
    "\n",
    "#Time domain:\n",
    "seconds = pd.get_dummies(data[u'seconds_remaining'].astype('category'))\n",
    "mins = pd.get_dummies(data[u'minutes_remaining'].astype('category'))\n",
    "seasons = pd.get_dummies(data[u'season'].astype('category'))\n",
    "period = pd.get_dummies(data[u'period'].astype('category'))\n",
    "\n",
    "#Spatial domain:\n",
    "distance = pd.get_dummies(data[u'shot_distance'].astype('category'))\n",
    "dummy_shot_type = pd.get_dummies(data[u'shot_type'].astype('category'))\n",
    "dummy_shot_zone_area = pd.get_dummies(data[u'shot_zone_area'].astype('category'))\n",
    "dummy_shot_zone_basic = pd.get_dummies(data[u'shot_zone_basic'].astype('category'))\n",
    "dummy_shot_zone_range = pd.get_dummies(data[u'shot_zone_range'].astype('category'))\n",
    "\n",
    "#dummy coded features\n",
    "action_type = pd.get_dummies(data[u'action_type'].astype('category'))\n",
    "dummy_combined_shot_type = pd.get_dummies(data[[u'combined_shot_type']])\n",
    "\n",
    "#Final Predictors\n",
    "X = data[[u'lat', u'lon', \n",
    "          u'seconds_remaining',\n",
    "          u'period',\n",
    "          u'game_date'\n",
    "         ]]\n",
    "X = pd.concat([X, \\\n",
    "               #Time\n",
    "               seconds,\\\n",
    "               mins, \\\n",
    "               period,\\\n",
    "               seasons,\\\n",
    "               #Type\n",
    "               action_type,\\\n",
    "               #Spatial\n",
    "               distance,\\\n",
    "               dummy_shot_zone_range,\\\n",
    "               dummy_shot_zone_area,\\\n",
    "               dummy_shot_zone_basic\\\n",
    "               ], axis = 1)\n",
    "\n",
    "X_test = X.head(5000)\n",
    "X_train = X.tail(25697)\n",
    "\n",
    "#Dependent\n",
    "y = data[u'shot_made_flag']\n",
    "y_test = y.head(5000)\n",
    "y_train = y.tail(25697)\n",
    "\n",
    "#\n",
    "Known_Data_Transformed = pd.concat([X_train,y_train],axis=1)\n",
    "Unknown_Data_Transformed = pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "predic_prob = np.zeros((5000,1),dtype=float)\n",
    "predic = np.zeros((5000,1),dtype=float)\n",
    "\n",
    "i=0\n",
    "start = 0\n",
    "for raw_date in pd.unique(Unknown_Data_Transformed['game_date']):\n",
    "    Sub_Known_Data_Transformed = Known_Data_Transformed[Known_Data_Transformed.apply(lambda x: x['game_date'] <= raw_date, axis=1)]\n",
    "    #Sub_Known_Data_Transformed = Known_Data_Transformed\n",
    "    Sub_Known_Data_Transformed = Sub_Known_Data_Transformed.drop(['game_date'], axis=1)\n",
    "    number_allowable_data = Sub_Known_Data_Transformed.shape[0]\n",
    "    #print(raw_date)\n",
    "    #print(number_allowable_data)\n",
    "    \n",
    "    #Dataframe to matrix training\n",
    "    X_sub_training = Sub_Known_Data_Transformed.drop(['shot_made_flag'], axis=1)\n",
    "    X_sub_training = X_sub_training.as_matrix()\n",
    "    y_sub_train = Sub_Known_Data_Transformed['shot_made_flag']\n",
    "    y_sub_train = y_sub_train.as_matrix()\n",
    "      \n",
    "    #Training Model\n",
    "    LR = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \\\n",
    "                            intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', \\\n",
    "                            max_iter=10000, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "    LR.fit(X_sub_training,y_sub_train)    \n",
    "    \n",
    "    #Prediction Process\n",
    "    to_predict = Unknown_Data_Transformed[Unknown_Data_Transformed.apply(lambda x: x['game_date'] == raw_date, axis=1)]\n",
    "    #to_predict = Unknown_Data_Transformed\n",
    "    to_predict = to_predict.drop(['shot_made_flag','game_date'], axis=1)\n",
    "    to_predict = to_predict.as_matrix()\n",
    "    y_predict_proba_LR = LR.predict_proba(to_predict)\n",
    "    number_predict = y_predict_proba_LR.shape[0]\n",
    "    y_predict_proba = y_predict_proba_LR[:,1]\n",
    "    y_predict_proba = y_predict_proba.reshape(-1,1)\n",
    "    predic_prob[start:start+number_predict] = y_predict_proba\n",
    "    y_predict = LR.predict(to_predict)\n",
    "    y_predict = y_predict.reshape(-1,1)\n",
    "    predic[start:start+number_predict] = y_predict\n",
    "    \n",
    "    #Prediction for next date\n",
    "    start = start+number_predict\n",
    "    if start >= 5000:\n",
    "        break\n",
    "y_test = Unknown_Data_Transformed['shot_made_flag']\n",
    "y_test = y_test.as_matrix()\n",
    "y_test_sub = y_test[0:start]\n",
    "accuracy = accuracy_score(y_test_sub, predic[0:start])\n",
    "score_test = log_loss(y_test_sub, predic_prob[0:start])\n",
    "print('accuracy %f' %accuracy)\n",
    "print('log loss %f' %score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "EE380L_HW2.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
