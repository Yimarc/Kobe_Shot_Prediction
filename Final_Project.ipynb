{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquaision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "playerID = \"977\"\n",
    "\n",
    "for season in range(1996,2016):\n",
    "    # The stats.nba.com API wants season as \"1996-97\"\n",
    "    seasonString = str(season) + '-' + str(season+1)[2:]\n",
    "    # The stats.nba.com endpoint we are using is http://stats.nba.com/stats/shotchartdetail\n",
    "    # More info on endpoints: https://github.com/seemethere/nba_py/wiki/stats.nba.com-Endpoint-Documentation\n",
    "    shot_chart_url = 'http://stats.nba.com/stats/shotchartdetail?Period=0&VsConference=&LeagueID=00&LastNGames=0&TeamID=0&PlayerPosition=&Position=&Location=&Outcome=&ContextMeasure=FGA&DateFrom=&StartPeriod=&DateTo=&OpponentTeamID=0&ContextFilter=&RangeType=&Season=' + seasonString + '&AheadBehind=&PlayerID=977&EndRange=&VsDivision=&PointDiff=&RookieYear=&GameSegment=&Month=0&ClutchTime=&StartRange=&EndPeriod=&SeasonType=Regular+Season&SeasonSegment=&GameID='\n",
    "    shot_chart_url = 'http://stats.nba.com/stats/shotchartdetail?Period=0&VsConference=&LeagueID=00&LastNGames=0&TeamID=0&PlayerPosition=&Position=&Location=&Outcome=&ContextMeasure=FGA&DateFrom=&StartPeriod=&DateTo=&OpponentTeamID=0&ContextFilter=&RangeType=&Season=' + seasonString + '&AheadBehind=&PlayerID=977&EndRange=&VsDivision=&PointDiff=&RookieYear=&GameSegment=&Month=0&ClutchTime=&StartRange=&EndPeriod=&SeasonType=Playoffs&SeasonSegment=&GameID='\n",
    "    #print(shot_chart_url)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30697\n"
     ]
    }
   ],
   "source": [
    "seasons = []\n",
    "for season in range(1996,2016):\n",
    "    seasonString = './regular/'+str(season) + '.json'\n",
    "    json_data=open(seasonString).read()\n",
    "    data = json.loads(json_data)\n",
    "    # Split response into headers and content\n",
    "    headers = data['resultSets'][0]['headers']\n",
    "    shots = data['resultSets'][0]['rowSet']\n",
    "    # Create pandas dataframe to hold the data\n",
    "    shot_df = pd.DataFrame(shots, columns=headers)\n",
    "    # add extra column for season\n",
    "    shot_df['SEASON'] = str(season) + '-' + str(season+1)[2:]\n",
    "    # add extra column for playoff flag\n",
    "    shot_df['playoffs'] = 0\n",
    "    seasons.append(shot_df)\n",
    "    \n",
    "for season in range(1996,2016):\n",
    "    seasonString = './playoffs/'+str(season) + '.json'\n",
    "    json_data=open(seasonString).read()\n",
    "    data = json.loads(json_data)\n",
    "    # Split response into headers and content\n",
    "    headers = data['resultSets'][0]['headers']\n",
    "    shots = data['resultSets'][0]['rowSet']\n",
    "    # Create pandas dataframe to hold the data\n",
    "    shot_df = pd.DataFrame(shots, columns=headers)\n",
    "    # add extra column for season\n",
    "    shot_df['SEASON'] = str(season) + '-' + str(season+1)[2:]\n",
    "    # add extra column for playoff flag\n",
    "    shot_df['playoffs'] = 1\n",
    "    seasons.append(shot_df)\n",
    "    \n",
    "kobe = pd.concat(seasons)\n",
    "print(len(kobe['GRID_TYPE']))    \n",
    "kobe.to_csv(\"kobe.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Recovery (SHOT_MADE_FLAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30697, 27)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "allData = pd.read_csv('data.csv', encoding='utf-8-sig')\n",
    "completeData = pd.read_csv('kobe.csv', encoding='utf-8-sig')\n",
    "referenceData = completeData[[u'GAME_ID',u'GAME_EVENT_ID',u'SHOT_MADE_FLAG']]\n",
    "referenceData['GAME_ID'] = referenceData['GAME_ID'].astype('int')\n",
    "referenceData['GAME_EVENT_ID'] = referenceData['GAME_EVENT_ID'].astype('int')\n",
    "referenceData['SHOT_MADE_FLAG'] = referenceData['SHOT_MADE_FLAG'].astype('float')\n",
    "unknown_data = allData[allData['shot_made_flag'].isnull()]#.reset_index()\n",
    "known_data = allData[allData['shot_made_flag'].notnull()]#.reset_index()\n",
    "\n",
    "for index,unknonw_i in unknown_data.iterrows():\n",
    "    game_id = unknonw_i['game_id']\n",
    "    event_id = unknonw_i['game_event_id']\n",
    "    true_i = referenceData.loc[(referenceData['GAME_ID']==(game_id)) & (referenceData['GAME_EVENT_ID'] == event_id)]    \n",
    "    true_flag = true_i['SHOT_MADE_FLAG'].values\n",
    "    unknown_data.set_value(index, 'shot_made_flag', true_flag)\n",
    "final_complete_data = unknown_data.append(known_data)\n",
    "\n",
    "list = []\n",
    "for row in final_complete_data['matchup']:\n",
    "    if '@' in str(row):\n",
    "        list.append(0)\n",
    "    else:\n",
    "        list.append(1)\n",
    "        \n",
    "final_complete_data['home_field'] = pd.DataFrame(list)\n",
    "final_complete_data = final_complete_data.reset_index()\n",
    "final_complete_data.to_csv('Complete_Data.csv')\n",
    "print(final_complete_data.shape) \n",
    "unknown_data = final_complete_data.head(5000)\n",
    "known_data = final_complete_data.tail(30697-5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discoverying features and corresponding hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6UAAAHVCAYAAAAJnF2uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1383a470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_name='season'\n",
    "data = known_data\n",
    "data[feature_name] = data[feature_name].astype('object')\n",
    "data_features = data[feature_name];\n",
    "data_features = pd.unique(data_features)\n",
    "#print(data_features)\n",
    "hit_rate = np.zeros((data_features.shape[0],1),dtype=np.float32)\n",
    "i = 0\n",
    "for type in data_features:\n",
    "    sub_type = data.loc[data[feature_name] == type]\n",
    "    nb_success_hit = sub_type.loc[sub_type['shot_made_flag'] == 1]\n",
    "    nb_success_hit = nb_success_hit.shape[0]\n",
    "    nb_fail_hit = sub_type.loc[sub_type['shot_made_flag'] == 0]\n",
    "    nb_fail_hit = nb_fail_hit.shape[0]\n",
    "    hit_rate[i] = nb_success_hit/(nb_success_hit+nb_fail_hit)\n",
    "    i = i+1\n",
    "hit_rate = hit_rate.reshape(-1)\n",
    "plt.figure(figsize=(16,8))    \n",
    "plt.bar(data_features,hit_rate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "def sort_and_partition(data, name, n):\n",
    "    stat = {}\n",
    "    for i, (d, x) in enumerate(zip(data[name], data['shot_made_flag'])):\n",
    "        if not (d in stat) :\n",
    "            stat[d] = [0, 0]\n",
    "        if x == 1:\n",
    "            stat[d][0] += 1\n",
    "            stat[d][1] += 1\n",
    "        else:\n",
    "            stat[d][1] += 1\n",
    "    for key, value in stat.items():\n",
    "        stat[key] = value[0] / value[1]\n",
    "    stat = sorted(stat.items(), key=operator.itemgetter(1))\n",
    "    index_map = {}\n",
    "    for i, (key, value) in enumerate(stat):\n",
    "        index_map[key] = math.floor(i / n)\n",
    "    length = math.ceil(len(stat) / n)\n",
    "    da = {}\n",
    "    zeros = [0 for i in range(length)]\n",
    "    for i in range(length):\n",
    "        da[name + str(i)] = []\n",
    "    for i, l in enumerate(data[name]):\n",
    "        for j in range(length):\n",
    "            if j == index_map[l]:\n",
    "                da[name + str(j)].append(1)\n",
    "            else:\n",
    "                da[name + str(j)].append(0)\n",
    "    return pd.DataFrame(data = da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing and features selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25697, 119)\n",
      "(5000, 119)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "## Decide the training set\n",
    "data = final_complete_data\n",
    "X = data[[#u'lat', \n",
    "          #u'lon', \n",
    "          u'shot_distance',\n",
    "          u'playoffs',\n",
    "          u'loc_x',\n",
    "          u'loc_y'\n",
    "         ]]\n",
    "\n",
    "## Quantization of features\n",
    "mins = sort_and_partition(data, 'minutes_remaining', 3)\n",
    "seasons = sort_and_partition(data, 'season', 1)\n",
    "seconds = sort_and_partition(data, 'seconds_remaining', 10)\n",
    "opponent = sort_and_partition(data, 'opponent', 3)\n",
    "\n",
    "## dummy coded features\n",
    "dummy_action_type = pd.get_dummies(data[[u'action_type']])\n",
    "dummy_combined_shot_type = pd.get_dummies(data[[u'combined_shot_type']])\n",
    "dummy_period = pd.get_dummies(data[[u'period']])      \n",
    "dummy_playoffs = pd.get_dummies(data[[u'playoffs']])\n",
    "dummy_opponent = pd.get_dummies(data[[u'opponent']])\n",
    "dummy_season = pd.get_dummies(data[[u'season']])\n",
    "dummy_shot_type = pd.get_dummies(data[[u'shot_type']])\n",
    "dummy_shot_zone_area = pd.get_dummies(data[[u'shot_zone_area']])\n",
    "dummy_shot_zone_basic = pd.get_dummies(data[[u'shot_zone_basic']])\n",
    "dummy_home_feild = pd.get_dummies(data[[u'home_field']])\n",
    "\n",
    "#Final Features\n",
    "X = pd.concat([X, \\\n",
    "               mins, \\\n",
    "               seconds,\\\n",
    "               seasons,\\\n",
    "               opponent,\\\n",
    "               dummy_home_feild,\\\n",
    "               dummy_action_type,\\\n",
    "               #dummy_combined_shot_type,\\\n",
    "               dummy_period,\\\n",
    "               dummy_shot_type,\\\n",
    "               dummy_shot_zone_area,\\\n",
    "               dummy_shot_zone_basic], axis = 1)\n",
    "X_train = X.tail(30697-5000)\n",
    "X_test = X.head(5000)\n",
    "X_train = X_train.as_matrix()\n",
    "X_test = X_test.as_matrix()\n",
    "\n",
    "#Scaling (Performance is not good)\n",
    "#X_train = preprocessing.scale(X_train)\n",
    "#X_test = preprocessing.scale(X_test)\n",
    "\n",
    "#Dependent\n",
    "y = data[[u'shot_made_flag']]\n",
    "y_train = y.tail(30697-5000)\n",
    "y_test = y.head(5000)\n",
    "y_train = y_train.as_matrix()\n",
    "y_test = y_test.as_matrix()\n",
    "\n",
    "#Print Shapoe\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss train: 0.604325\n",
      "Log loss test: 0.608044\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "\n",
    "LR = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \\\n",
    "                        intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', \\\n",
    "                        max_iter=10000, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "LR.fit(X_train,y_train)\n",
    "y_predict_proba_LR = LR.predict_proba(X_test)\n",
    "score_test = log_loss(y_test, y_predict_proba_LR[:,1])\n",
    "y_predict_proba_LR_train = LR.predict_proba(X_train)\n",
    "score_training= log_loss(y_train, y_predict_proba_LR_train[:,1])\n",
    "print('Log loss train: %f' %score_training)\n",
    "print('Log loss test: %f' %score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold LR (Deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.610125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_folds = 6\n",
    "kf = KFold(n_folds)\n",
    "kf.get_n_splits(X_all)\n",
    "logloss = np.zeros((1,n_folds),dtype=np.double)\n",
    "for k, (train, test) in enumerate(kf.split(X_train,y_train)):\n",
    "     LR = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \\\n",
    "                         intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', \\\n",
    "                         max_iter=10000, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "     LR.fit(X_train[train],y_train[train])\n",
    "     y_predict_proba_LR_kfold = LR.predict_proba(X_train[test])\n",
    "     logloss[0][k] = log_loss(y_train[test], y_predict_proba_LR_kfold[:,1])\n",
    "print('Log loss: %f' %np.mean(logloss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree with gini criterion\n",
      "Log loss: 0.626109\n",
      "Decision tree with entropy criterion\n",
      "Log loss: 0.626109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "print('Decision tree with gini criterion')\n",
    "clf_gini = tree.DecisionTreeClassifier(criterion = 'gini', max_depth = 2)\n",
    "clf_gini.fit(X_train, y_train)\n",
    "y_predict_proba_clf_gini = clf_gini.predict_proba(X_test)\n",
    "score = log_loss(y_test, y_predict_proba_clf_gini[:,1]) \n",
    "print('Log loss: %f' %score)\n",
    "\n",
    "print('Decision tree with entropy criterion')\n",
    "clf_entropy = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 2)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "y_predict_proba_clf_entropy = clf_entropy.predict_proba(X_test)\n",
    "score = log_loss(y_test, y_predict_proba_clf_entropy[:,1]) \n",
    "print('Log loss: %f' %score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter 'n_estimators' is: 200\n",
      "The best parameter 'criterion' is: entropy\n",
      "The testing accuracy (accuracy_score) is: 0.662646\n",
      "The roc_auc_score is: 0.689162\n",
      "Logloss: 0.656114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier)\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "parameters_RFC = {'n_estimators':[100],'criterion':['entropy'],'random_state':[42]}\n",
    "grid_search_RFC = GridSearchCV(RFC, parameters_RFC)                             \n",
    "grid_search_RFC.fit(X_train,y_train)\n",
    "best_n_estimators_RFC = grid_search_RFC.best_params_['n_estimators']\n",
    "best_criterion_RFC = grid_search_RFC.best_params_['criterion']\n",
    "\n",
    "RFC_Best = RandomForestClassifier(n_estimators=best_n_estimators_RFC, criterion=best_criterion_RFC, random_state=42)\n",
    "RFC_Best.fit(X_train,y_train)\n",
    "y_predict_proba_RFC = RFC_Best.predict_proba(X_test)\n",
    "accuracy_score_RFC = accuracy_score(y_test, RFC_Best.predict(X_test))\n",
    "roc_auc_score_RFC = roc_auc_score(y_test, y_predict_proba_RFC[:,1])\n",
    "score = log_loss(y_test, y_predict_proba_RFC[:,1])\n",
    "\n",
    "#print('The best parameter \\'n_estimators\\' is: %d' %best_n_estimators_RFC)\n",
    "#print('The best parameter \\'criterion\\' is: %s' %best_criterion_RFC)\n",
    "#print('The testing accuracy (accuracy_score) is: %f' %accuracy_score_RFC)\n",
    "print('The roc_auc_score is: %f' %roc_auc_score_RFC)\n",
    "print('Logloss: %f' %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.607497\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,log_loss)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {'n_estimators':[200],\\\n",
    "#               'learning_rate':[0.03],\\\n",
    "#               'max_depth':[6],\\\n",
    "#              }\n",
    "# XGB = XGBClassifier(num_class=2,objective='multi:softprob')\n",
    "# grid_search_XGB = GridSearchCV(XGB, parameters)                             \n",
    "# grid_search_XGB.fit(X_train,y_train)\n",
    "# best_n_estimators_XGB = grid_search_XGB.best_params_['n_estimators']\n",
    "# best_learning_rate_XGB = grid_search_XGB.best_params_['learning_rate']\n",
    "# best_max_depth_XGB = grid_search_XGB.best_params_['max_depth']\n",
    "\n",
    "# XGB_Best = XGBClassifier(n_estimators=best_n_estimators_XGB,\\\n",
    "#                           learning_rate=best_learning_rate_XGB,\\\n",
    "#                      num_class=2,\\\n",
    "#                      min_child_weight = 9,\\\n",
    "#                      max_depth=best_max_depth_XGB,\\\n",
    "#                      objective='multi:softprob')\n",
    "\n",
    "XGB_Best = XGBClassifier(n_estimators=200,\\\n",
    "                         learning_rate=0.033,\\\n",
    "                         num_class=2,\\\n",
    "                         min_child_weight = 9,\\\n",
    "                         max_depth=7,\\\n",
    "                         objective='multi:softprob')\n",
    "\n",
    "XGB_Best.fit(X_train,y_train)\n",
    "y_predict_proba_XGB = XGB_Best.predict_proba(X_test)\n",
    "accuracy_score_XGB = accuracy_score(y_test, XGB_Best.predict(X_test))\n",
    "roc_auc_score_XGB = roc_auc_score(y_test, y_predict_proba_XGB[:,1])\n",
    "score = log_loss(y_test, y_predict_proba_XGB[:,1])\n",
    "print('Log loss: %f' %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFolk XBoost (Deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.model_selection import KFold\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# n_folds = 6\n",
    "# kf = KFold(n_folds)\n",
    "# kf.get_n_splits(X_all)\n",
    "# logloss = np.zeros((1,n_folds),dtype=np.double)\n",
    "# for k, (train, test) in enumerate(kf.split(X_train,y_train)):\n",
    "#     XGB_Best = XGBClassifier(n_estimators=100,\\\n",
    "#                              learning_rate=0.04,\\\n",
    "#                              num_class=2,\\\n",
    "#                              min_child_weight = 9,\\\n",
    "#                              max_depth=7,\\\n",
    "#                              objective='multi:softprob')\n",
    "#     XGB_Best.fit(X_train[train],y_train[train])\n",
    "#     y_predict_proba_XGB_kfold = XGB_Best.predict_proba(X_train[test])\n",
    "#     logloss[0][k] = log_loss(y_train[test], y_predict_proba_XGB_kfold[:,1])\n",
    "# print('Log loss: %f' %np.mean(logloss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "EE380L_HW2.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
